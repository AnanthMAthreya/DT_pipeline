{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.components as comp\n",
    "import requests\n",
    "import kfp.dsl as dsl\n",
    "from kfp.dsl import pipeline, component,Dataset,Output,Input,Model\n",
    "@component(\n",
    "    base_image='python:3.13.1',\n",
    "    packages_to_install=['pandas==2.2.3', 'numpy==2.2.0']\n",
    ")\n",
    "def prepare_data(output_data: Output[Dataset]):\n",
    "    import pandas as pd\n",
    "    print(\"Inside prepare data component\")\n",
    "    data = pd.read_csv(\"https://raw.githubusercontent.com/AnanthMAthreya/DT_pipeline/main/dataset.csv\")\n",
    "    \n",
    "    data['Attrition']=data['Attrition'].map({\"Yes\":1,\"No\":0}).astype(int)\n",
    "    data['BusinessTravel'] = data['BusinessTravel'].astype(str)\n",
    "    data['BusinessTravel'] = data['BusinessTravel'].str.strip()\n",
    "    data['BusinessTravel'] = data['BusinessTravel'].map(\n",
    "    {'Non-travel': 0, 'Travel_Rarely': 1, 'Travel_Frequently': 2})\n",
    "    data['BusinessTravel'] = data['BusinessTravel'].fillna(0)\n",
    "    data['Department']=data['Department'].map({'Sales':0, 'Research & Development':1, 'Human Resources':2}).astype(int)\n",
    "    data['EducationField']=data['EducationField'].map({'Life Sciences':1,'Other':0,'Medical':2,'Marketing':3,'Technical Degree':4,'Human Resources':5}).astype(int)\n",
    "    data['Gender']=data['Gender'].map({'Female':0, 'Male':1}).astype(int)\n",
    "    data['JobRole']=data['JobRole'].map({'Sales Executive':0, 'Research Scientist':1, 'Laboratory Technician':2,\n",
    "       'Manufacturing Director':3, 'Healthcare Representative':4, 'Manager':5,\n",
    "       'Sales Representative':6, 'Research Director':7, 'Human Resources':8}).astype(int)\n",
    "    data['MaritalStatus']=data['MaritalStatus'].map({'Single':0, 'Married':1, 'Divorced':2}).astype(int)\n",
    "    data['OverTime']=data['OverTime'].map({'Yes':1,'No':0}).astype(int)\n",
    "    data.to_csv(output_data.path, index=False)\n",
    "    print('The prepared data is saved in final_data.csv artifact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image='python:3.13.1',packages_to_install=['pandas==2.2.3','numpy==2.2.0','scikit-learn==1.6.0'])\n",
    "def train_test_split(input_data: Input[Dataset], output_train_data: Output[Dataset], output_test_data: Output[Dataset]):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    print(\"---- Inside train_test_split component ----\")\n",
    "    data=pd.read_csv(input_data.path)\n",
    "    features=['Age','BusinessTravel','DailyRate', 'Department','DistanceFromHome', 'Education', 'EducationField', 'EnvironmentSatisfaction', 'Gender', 'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome','MonthlyRate', 'NumCompaniesWorked', 'OverTime', 'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'TotalWorkingYears','TrainingTimesLastYear','WorkLifeBalance','YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion','YearsWithCurrManager']\n",
    "    X=data[features]\n",
    "    y=data['Attrition']\n",
    "    X_train,X_test,y_train,y_test=tts(X,y,test_size=0.3,stratify=y,random_state=47)\n",
    "    os.makedirs(output_train_data.path, exist_ok=True)\n",
    "    os.makedirs(output_test_data.path, exist_ok=True)\n",
    "    \n",
    "    # Save data as .npy files\n",
    "    np.save(os.path.join(output_train_data.path, 'X_train.npy'), X_train)\n",
    "    np.save(os.path.join(output_train_data.path, 'y_train.npy'), y_train)\n",
    "    np.save(os.path.join(output_test_data.path, 'X_test.npy'), X_test)\n",
    "    np.save(os.path.join(output_test_data.path, 'y_test.npy'), y_test)\n",
    "    \n",
    "    print(\"All the 4 parts have been saved\")\n",
    "    print(\"All the 4 parts have been saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image='python:3.13.1', packages_to_install=['pandas==2.2.3', 'numpy==2.2.0', 'scikit-learn==1.6.0'])\n",
    "def train_decision_tree(input_train_data: Input[Dataset], output_model: Output[Model]):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import os\n",
    "    from sklearn import tree\n",
    "    print(\"Inside decision-tree-classifier\")\n",
    "\n",
    "    # Load training data\n",
    "    X_train = np.load(input_train_data.path + '/X_train.npy', allow_pickle=True)\n",
    "    y_train = np.load(input_train_data.path + '/y_train.npy', allow_pickle=True)\n",
    "\n",
    "    # Initialize and train the decision tree model\n",
    "    model = tree.DecisionTreeClassifier(max_depth=4)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Create the model output directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_model.path), exist_ok=True)\n",
    "\n",
    "    # Save the model\n",
    "    with open(output_model.path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    print(\"The decision tree model is saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image='python:3.13.1',packages_to_install=['pandas==2.2.3','numpy==2.2.0','scikit-learn==1.6.0'])\n",
    "def get_metrics(input_train_data: Input[Dataset], input_test_data: Input[Dataset], input_model: Input[Model]):\n",
    "    from sklearn.metrics import confusion_matrix as cm\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    X_train = np.load(input_train_data.path + '/X_train.npy', allow_pickle=True)\n",
    "    y_train = np.load(input_train_data.path + '/y_train.npy', allow_pickle=True)\n",
    "    X_test = np.load(input_test_data.path + '/X_test.npy', allow_pickle=True)\n",
    "    y_test = np.load(input_test_data.path + '/y_test.npy', allow_pickle=True)\n",
    "    with open(input_model.path,'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    y_pred_train=model.predict(X_train)\n",
    "    cm1=cm(y_train,y_pred_train)\n",
    "    acc1=(cm1[0,0]+cm1[1,1])/sum([sum(i) for i in cm1])\n",
    "    print(\"The train accuracy is \",acc1)\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    cm2=cm(y_test,y_pred_test)\n",
    "    acc2=(cm2[0,0]+cm2[1,1])/sum([sum(i) for i in cm2])\n",
    "    print(\"The test accuracy is \",acc2)\n",
    "    print(\"THe difference in the accuracies is \",abs(acc1-acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "   name='Decision tree classifier Kubeflow Demo Pipeline',\n",
    "   description='A sample pipeline that performs Decision tree classifier'\n",
    ")\n",
    "def dt_pipeline():\n",
    "    prepare_data_task = prepare_data()\n",
    "    train_test_split_task = train_test_split(input_data=prepare_data_task.outputs['output_data']).after(prepare_data_task)\n",
    "    train_decision_tree_task = train_decision_tree(input_train_data=train_test_split_task.outputs['output_train_data']).after(train_test_split_task)\n",
    "    get_metrics_task = get_metrics(\n",
    "        input_train_data=train_test_split_task.outputs['output_train_data'],\n",
    "        input_test_data=train_test_split_task.outputs['output_test_data'],\n",
    "        input_model=train_decision_tree_task.outputs['output_model']\n",
    "    ).after(train_decision_tree_task)\n",
    "    prepare_data_task.set_caching_options(False)\n",
    "    train_test_split_task.set_caching_options(False)\n",
    "    train_decision_tree_task.set_caching_options(False)\n",
    "    get_metrics_task.set_caching_options(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=dt_pipeline,\n",
    "    package_path='dt_pipeline2.yaml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
